{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eduardodarocha/projeto_transfer_learning_python_DIO/blob/main/projeto_transfer_learning_python_DIO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "45ticwyzsuqg"
      },
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning - Problema cats x dogs\n",
        "\n",
        "Implementação de rede convolucional usando transfer learning para diferenciação das categorias gato e cachorro.\n",
        "\n",
        " O banco de dados original se encontra [aqui](https://www.kaggle.com/c/dogs-vs-cats). Dentre essas imagens foram separadas 8000 imagens para treinamento e 2000 imagens para teste.\n",
        "\n",
        "Todo o código foi feito no Colab e pode ser compilado online em [https://colab.research.google.com](https://colab.research.google.com).\n",
        "\n",
        "\n",
        "** Autor: Eduardo Rocha**\n",
        "\n",
        "\n",
        "Github: [https://github.com/eduardodarocha](https://github.com/eduardodarocha)"
      ]
    },
    {
      "metadata": {
        "id": "wvFs0wxIu7-n"
      },
      "cell_type": "markdown",
      "source": [
        "## Procedimentos Iniciais"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apagar a pasta catsxdogs caso algum novo dado seja incluído na pasta:"
      ],
      "metadata": {
        "id": "CWlegCQxXbN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm -rf projeto_transfer_learning_python_DIO"
      ],
      "metadata": {
        "id": "WUoJiMaYXT8V"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CwN6J1f0vUxW"
      },
      "cell_type": "markdown",
      "source": [
        "Download da pasta:"
      ]
    },
    {
      "metadata": {
        "id": "u_eqqa_6eZT_"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/eduardodarocha/projeto_transfer_learning_python_DIO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A3A7Y7GbvY2Y"
      },
      "cell_type": "markdown",
      "source": [
        "Importação dos pacotes:"
      ]
    },
    {
      "metadata": {
        "id": "7q906nBeeHAo"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense,GlobalAveragePooling2D\n",
        "from keras.applications import MobileNet\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CbSaiWG3v2kB"
      },
      "cell_type": "markdown",
      "source": [
        "## Transfer learning:"
      ]
    },
    {
      "metadata": {
        "id": "ZGFvuzY2v-Sm"
      },
      "cell_type": "markdown",
      "source": [
        "Importando o modelo MobileNet que foi previamente treinado no ImageNet e descartando a última camada de neurônios:"
      ]
    },
    {
      "metadata": {
        "id": "1B3-bKjBwReh"
      },
      "cell_type": "code",
      "source": [
        "model=MobileNet(weights='imagenet',include_top=False, input_shape=(224, 224, 3))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oO7FN2qEwgkf"
      },
      "cell_type": "markdown",
      "source": [
        "Criando a saída do modelo MobileNet:"
      ]
    },
    {
      "metadata": {
        "id": "PwwGWkXWwi9G"
      },
      "cell_type": "code",
      "source": [
        "x=model.output\n",
        "x=GlobalAveragePooling2D()(x)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m34KAC6_wsPu"
      },
      "cell_type": "markdown",
      "source": [
        "Adicionando uma camada intermediária e a camada final:"
      ]
    },
    {
      "metadata": {
        "id": "f-g5WXZ2ebil"
      },
      "cell_type": "code",
      "source": [
        "x=Dense(50,activation='relu')(x)\n",
        "preds=Dense(1,activation='sigmoid')(x)\n",
        "model=Model(inputs=model.input,outputs=preds)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "id": "upU4C7VyxJN7"
      },
      "cell_type": "markdown",
      "source": [
        "Visualizando todas as camadas da nova rede criada usando o modelo MobileNetV2:"
      ]
    },
    {
      "metadata": {
        "id": "2VemyqKtfGdM",
        "outputId": "08264287-10fd-4f5d-ce59-879c766528c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "for i,layer in enumerate(model.layers):\n",
        "  print(i,layer.name)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_layer\n",
            "1 conv1\n",
            "2 conv1_bn\n",
            "3 conv1_relu\n",
            "4 conv_dw_1\n",
            "5 conv_dw_1_bn\n",
            "6 conv_dw_1_relu\n",
            "7 conv_pw_1\n",
            "8 conv_pw_1_bn\n",
            "9 conv_pw_1_relu\n",
            "10 conv_pad_2\n",
            "11 conv_dw_2\n",
            "12 conv_dw_2_bn\n",
            "13 conv_dw_2_relu\n",
            "14 conv_pw_2\n",
            "15 conv_pw_2_bn\n",
            "16 conv_pw_2_relu\n",
            "17 conv_dw_3\n",
            "18 conv_dw_3_bn\n",
            "19 conv_dw_3_relu\n",
            "20 conv_pw_3\n",
            "21 conv_pw_3_bn\n",
            "22 conv_pw_3_relu\n",
            "23 conv_pad_4\n",
            "24 conv_dw_4\n",
            "25 conv_dw_4_bn\n",
            "26 conv_dw_4_relu\n",
            "27 conv_pw_4\n",
            "28 conv_pw_4_bn\n",
            "29 conv_pw_4_relu\n",
            "30 conv_dw_5\n",
            "31 conv_dw_5_bn\n",
            "32 conv_dw_5_relu\n",
            "33 conv_pw_5\n",
            "34 conv_pw_5_bn\n",
            "35 conv_pw_5_relu\n",
            "36 conv_pad_6\n",
            "37 conv_dw_6\n",
            "38 conv_dw_6_bn\n",
            "39 conv_dw_6_relu\n",
            "40 conv_pw_6\n",
            "41 conv_pw_6_bn\n",
            "42 conv_pw_6_relu\n",
            "43 conv_dw_7\n",
            "44 conv_dw_7_bn\n",
            "45 conv_dw_7_relu\n",
            "46 conv_pw_7\n",
            "47 conv_pw_7_bn\n",
            "48 conv_pw_7_relu\n",
            "49 conv_dw_8\n",
            "50 conv_dw_8_bn\n",
            "51 conv_dw_8_relu\n",
            "52 conv_pw_8\n",
            "53 conv_pw_8_bn\n",
            "54 conv_pw_8_relu\n",
            "55 conv_dw_9\n",
            "56 conv_dw_9_bn\n",
            "57 conv_dw_9_relu\n",
            "58 conv_pw_9\n",
            "59 conv_pw_9_bn\n",
            "60 conv_pw_9_relu\n",
            "61 conv_dw_10\n",
            "62 conv_dw_10_bn\n",
            "63 conv_dw_10_relu\n",
            "64 conv_pw_10\n",
            "65 conv_pw_10_bn\n",
            "66 conv_pw_10_relu\n",
            "67 conv_dw_11\n",
            "68 conv_dw_11_bn\n",
            "69 conv_dw_11_relu\n",
            "70 conv_pw_11\n",
            "71 conv_pw_11_bn\n",
            "72 conv_pw_11_relu\n",
            "73 conv_pad_12\n",
            "74 conv_dw_12\n",
            "75 conv_dw_12_bn\n",
            "76 conv_dw_12_relu\n",
            "77 conv_pw_12\n",
            "78 conv_pw_12_bn\n",
            "79 conv_pw_12_relu\n",
            "80 conv_dw_13\n",
            "81 conv_dw_13_bn\n",
            "82 conv_dw_13_relu\n",
            "83 conv_pw_13\n",
            "84 conv_pw_13_bn\n",
            "85 conv_pw_13_relu\n",
            "86 global_average_pooling2d\n",
            "87 dense\n",
            "88 dense_1\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "MKJNIAKBybNY"
      },
      "cell_type": "markdown",
      "source": [
        "Definindo qual camada da rede será treinada. Nesse caso somente as duas últimas camadas adicionadas:"
      ]
    },
    {
      "metadata": {
        "id": "55aGsU4ufgJE"
      },
      "cell_type": "code",
      "source": [
        "for layer in model.layers[:88]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[88:]:\n",
        "    layer.trainable=True"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SDq6-50Jy1xv"
      },
      "cell_type": "markdown",
      "source": [
        "## ImageDataGenerator"
      ]
    },
    {
      "metadata": {
        "id": "ofmdrIHVy5j0"
      },
      "cell_type": "markdown",
      "source": [
        "Definindo o tamanho de cada batch:"
      ]
    },
    {
      "metadata": {
        "id": "nYPnSrmQhDSq"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FoUT3HQZzUm_"
      },
      "cell_type": "markdown",
      "source": [
        "Cada imagem do banco será apresentada a rede de uma forma diferente através do ImageDataGenerator:"
      ]
    },
    {
      "metadata": {
        "id": "aOePa8OAgOaf",
        "outputId": "e98863b8-d21a-463f-b9cc-0cf80f4b4a0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.4,\n",
        "                                   zoom_range = 0.4,\n",
        "                                   height_shift_range=0.3,\n",
        "                                   width_shift_range=0.3,\n",
        "                                   rotation_range=50,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('projeto_transfer_learning_python_DIO/training_set',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = batch_size,\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('projeto_transfer_learning_python_DIO/test_set',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = batch_size,\n",
        "                                            class_mode = 'binary')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "zN0NGzrc0QMH"
      },
      "cell_type": "markdown",
      "source": [
        "## Treinamento"
      ]
    },
    {
      "metadata": {
        "id": "DlozFnpQ0WW2"
      },
      "cell_type": "markdown",
      "source": [
        "Definindo os parâmetros de compilação da rede:"
      ]
    },
    {
      "metadata": {
        "id": "lpeqcs5hgkd8"
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate = 0.0001),loss='binary_crossentropy',metrics=['accuracy'])\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bb1x9_kz0i4P"
      },
      "cell_type": "markdown",
      "source": [
        "Fazendo o treinamento da rede:"
      ]
    },
    {
      "metadata": {
        "id": "3tzvbgsYhkDK"
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(x=training_set,\n",
        "                   steps_per_epoch=int(8000/batch_size),\n",
        "                   epochs=10,\n",
        "                   validation_data = test_set,\n",
        "                   validation_steps = int(2000/batch_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bpE6bcT4DgXC"
      },
      "cell_type": "markdown",
      "source": [
        "Salvando o modelo para utilização futura:"
      ]
    },
    {
      "metadata": {
        "id": "9bKzjWBbnXaM"
      },
      "cell_type": "code",
      "source": [
        "model.save('projeto_transfer_learning_python_DIO/catsxdogs_mobilenet.h5') #This file format is considered legacy\n",
        "# model.save('projeto_transfer_learning_python_DIO/catsxdogs.keras')\n",
        "from google.colab import files\n",
        "# files.download('catsxdogs_mobilenet.h5')\n",
        "files.download('projeto_transfer_learning_python_DIO/catsxdogs.keras')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kBLPwHxpC7MG"
      },
      "cell_type": "markdown",
      "source": [
        "## Previsão"
      ]
    },
    {
      "metadata": {
        "id": "IupvsIC2DHJD"
      },
      "cell_type": "markdown",
      "source": [
        "Mostrando os arquivos da pasta single_prediction com imagens inéditas para a rede classificar:"
      ]
    },
    {
      "metadata": {
        "id": "-zi2res8DTo4",
        "outputId": "23b89c9a-a71c-4d86-9f0e-a127b0d881e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "ls projeto_transfer_learning_python_DIO/single_prediction/"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat_or_dog_1.jpg  chino1.jpg  floyd2.jpg  floyd4.jpg\n",
            "cat_or_dog_2.jpg  floyd1.jpg  floyd3.jpg\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "CjZPIcKiC-9_"
      },
      "cell_type": "markdown",
      "source": [
        "Escolhendo uma imagem da pasta single_prediction para fazer a previsão:"
      ]
    },
    {
      "metadata": {
        "id": "9qlK2kkPoMD1"
      },
      "cell_type": "code",
      "source": [
        "test_image = image.load_img('projeto_transfer_learning_python_DIO/single_prediction/cat_or_dog_2.jpg', target_size = (224, 224))\n",
        "\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "test_image = test_image/255"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lfF9Lf-XoRgH",
        "outputId": "5096ac5c-f49a-4d7f-fb6c-57b56b8aa29f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "result = model.predict(test_image)\n",
        "\n",
        "if result[0][0] > 0.5:\n",
        "    prediction = 'dog'\n",
        "else:\n",
        "    prediction = 'cat'\n",
        "\n",
        "print(prediction)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729ms/step\n",
            "cat\n"
          ]
        }
      ]
    }
  ]
}